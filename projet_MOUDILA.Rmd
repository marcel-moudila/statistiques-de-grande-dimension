---
title: "Projet"
author: "MOUDILA Marcel"
date: "`r Sys.Date()`"
output: pdf_document
---

**Abstract**: This collection of data is part of the RNA-Seq (HiSeq) PANCAN data set, it is a random extraction of gene expressions of patients having different types of tumor: BRCA, KIRC, COAD, LUAD and PRAD.

|                                |                            |
|--------------------------------|----------------------------|
| **Data Set Characteristics:**  | Multivariate               |
| **Attribute Characteristics:** | Real                       |
| **Associated Tasks:**          | Classification, Clustering |
| **Number of Instances:**       | 801                        |
| **Number of Attributes:**      | 20531                      |
| **Missing Values?**            | N/A                        |

**Data Set Information:**

Samples (instances) are stored row-wise. Variables (attributes) of each sample are RNA-Seq gene expression levels measured by illumina HiSeq platform.

**Attribute Information:**

A dummy name (gene_XX) is given to each attribute. The attributes are ordered consitently with the original submission.

```{r include=FALSE}
library(data.table)
data = fread("/home/moudilamarcel/Bureau/data.csv")
labels = fread("/home/moudilamarcel/Bureau/labels.csv", header = TRUE)
data = as.data.frame(data[,-1])
labels = as.data.frame(labels[,-1])

# quelques manipulations
names(labels) = "Class"
labels$Class = as.factor(labels$Class)
df = cbind.data.frame(labels,data)
```

Steps :

1.  Data analysis

2.  Anova's test and Bonferroni's test to reduce the size

3.  missing values analysis

4.  training 1: logistic regression

5.  training 2: random forest

6.  training 3: linear discriminant analysis

# Data analysis

Our dataset has big size (801,20532), no missing values. The target is of type categorical, this is classification's problem.

|       | BRCA | COAD | KIRC | LUAD | PRAD |
|-------|------|------|------|------|------|
| Count | 300  | 78   | 146  | 141  | 136  |
|       |      |      |      |      |      |

: Table of count

```{r echo=TRUE}
# size of dataset
dim(df)
```

```{r echo=TRUE}
# sum of missing values
p = dim(df)[2]
valManq = c()
for (j in 1:p){
  valManq = c(valManq,sum(is.na(df[,j])))
}
sum(valManq)
```

```{r echo=TRUE}
# count by label
table(df$Class)
```

```{r echo=TRUE}

sum(table(df$Class))
```

Our dataset has predictors which not variate.

```{r}
p = dim(df)[2]
ind = c()
for (j in 2:p){
  if (min(df[,j])== max(df[,j])){
    ind = c(ind,j)
  }
}
length(ind)
```

```{}
```

```{}
```

```{r echo=TRUE}
# delete 
df2 = copy(df)
df2 = df[,-ind]
dim(df2)
```

```{r echo=TRUE}
library(caret)
```

# Anova's test and Bonferroni's test to reduce the size

```{r}
# created pvalues's vector
vecteur_pv = c()
p = dim(df2)[2]
for (i in 2:p){
  pv = anova(lm(df2[,i] ~ df2$Class))$`Pr(>F)`[1]
  vecteur_pv = c(vecteur_pv, pv)
}
```

```{r echo=TRUE}
length(vecteur_pv) 
```

```{r}
summary(vecteur_pv)
```

```{r}
# calculated the adjust pvalues
adj.pv = p.adjust(vecteur_pv,"bonferroni")
indCol_adj = which(adj.pv >=0.1)
length(indCol_adj)    # number of not significant test by Bonferroni
```

```{r echo=TRUE}
# mon nouveau dataset
ind = indCol_adj + 1
df3 = copy(df2)
df3 = df3[,-ind]
dim(df3)
```

# training set and testing set

```{r}
set.seed(1234)
df4 = df3[sample(nrow(df3)),]
train = df4[1:600,]
test = df4[-(1:600),]
X_train = train[,2:18379] 
y_train = train[,1]
X_test = test[,2:18379]
y_test = test[,1]
```

```{r echo=TRUE}
table(y_train)
```

```{r echo=TRUE}
table(y_test)
```

# studies of correlations between predictors

```{r echo=TRUE}
descrCor <-  cor(X_train)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
```

```{r echo=TRUE}
summary(descrCor[upper.tri(descrCor)])
```

```{r echo=TRUE}
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
# nouveau X_train
X_train <- X_train[,-highlyCorDescr]
dim(X_train)
```

```{r}
write.csv2(X_train,file="Xtrain.csv")
```

```{r echo=TRUE}
# nouveau X_test
X_test <- X_test[,-highlyCorDescr]
dim(X_test)
```

```{r}
write.csv2(X_test,file="Xtest.csv")
```

# Sparse PCA because dataset size is large

```{r echo=TRUE}
library(elasticnet)
zz = X_train
mat = data.matrix(zz,rownames.force = NA)
sparse.pca.result = spca(mat,K=3, type="predictor",sparse ="varnum",para =c(10,10,10))
```

```{r echo=TRUE}
ind <- which(sparse.pca.result$loadings[,]!=0,arr.ind=TRUE)
res <- sparse.pca.result$loadings[ind[,1],]
rownames(res) <- ind[,1]
res
```

```{r}
ind <- read.csv("~/MCAD Marcel/Stat de grande dimension/projet/ind.csv", sep=";")
```

```{r echo=TRUE}
# nouveau X_train
X_trainFinal = X_train[ind[,2]]
dim(X_trainFinal)
```

```{r echo=TRUE}
# nouveau X_test
X_testFinal = X_test[ind[,2]]
dim(X_testFinal)
```

```{r}
y_trainFinal = y_train
length(y_trainFinal)
```

```{r}
y_testFinal = y_test
length(y_testFinal)
```

```{r}
write.csv2(X_trainFinal,file="XtrainFinal.csv")
write.csv2(X_testFinal,file="XtestFinal.csv")
write.csv2(y_trainFinal,file="ytrainFinal.csv")
write.csv2(y_testFinal,file="ytestFinal.csv")
```

# training

## Logistic regression

```{r include=FALSE}
# cross-validation avec 10 folds
fitControl <- trainControl(method = "cv", number = 10)
```

```{r include=FALSE}
# rÃ©gression logistique multinomiale

regLogistique <- train(X_trainFinal, y_trainFinal, 
                 method = "multinom",
                 trControl = fitControl,
                 metric = "Accuracy",
                 trace = FALSE)
```

```{r}
regLogistique
```

```{r}
# prediction
pred_regLogistique <- predict(regLogistique, X_test)
```

```{r}
# score on testing dataset
postResample(pred = pred_regLogistique, obs = y_test)
```

## Random Forest

```{r include=FALSE}
# random forest
randomForest <- train(X_trainFinal, y_trainFinal, 
                 method = "rf",
                 trControl = fitControl,
                 metric = "Accuracy")
```

```{r}
randomForest
```

```{r}
pred_randomForest <- predict(randomForest, X_test)
```

```{r}
# score on testing dataset
postResample(pred = pred_randomForest, obs = y_test)
```

## linear discriminant analysis

```{r include=FALSE}
ADL <- train(X_trainFinal, y_trainFinal, 
                 method = "lda2",
                 trControl = fitControl,
                 metric = "Accuracy")
```

```{r}
ADL
```

```{r}
pred_ADL <- predict(ADL, X_testFinal)
```

```{r}
# score on testing dataset 
postResample(pred = pred_ADL, obs = y_test)
```

# The best: Random forest

# Other method : SPLSDA (my preference)

```{r echo=TRUE}
library(MASS)
library(rgl)
library(lattice)
library(pheatmap)
library(mixOmics)
```

```{r echo=TRUE}
X_train = train[,2:18379]
X_test = test[,2:18379]
X_train <- X_train[,-highlyCorDescr]
X_test <- X_test[,-highlyCorDescr]

mat = data.matrix(X_train,rownames.force = NA)

tumeursplsda <-splsda(mat, y_train, ncomp = 3, keepX = rep(10,3))
```

```{r echo=TRUE}
ind <- which(tumeursplsda$loadings$X[,]!=0,arr.ind=TRUE)
res <- tumeursplsda$loadings$X[ind[,1],]
rownames(res) <- ind[,1]
```

```{r}
plotIndiv(tumeursplsda, ind.names = y_train, legend = TRUE, ellipse =TRUE)
```

```{r include=FALSE}
tumeur.5foldda <- perf(tumeursplsda, validation = "Mfold", folds = 5,
dist = "all", auc = TRUE)
```

```{r echo=TRUE}
tumeur.5foldda$auc
```
